{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For cats, we definitely see a strong trend toward the weighted average as the count of pets goes up above 25. We see a similar trend for dogs, but we don't see as much of a convergence toward the weighted average until we get to breeds with counts over 125.\n",
    "\n",
    "It does seem to make sense that we should pick a threshold as our minimum count of pets per breed. Choosing this threshold is not as straightforward though. \n",
    "\n",
    "Here's a list of the steps we'll follow:\n",
    "1. Set threshold and save a list of breeds with counts greater or equal to the threshold\n",
    "2. Write a function to update the breed for a row based on whether or not it exists in the list from step 1\n",
    "3. Create a copy of our original df and apply the function\n",
    "4. Print out the before and after numbers for our count of unique breeds\n",
    "\n",
    "As part of step 2 above, we'll update the breed name for breeds with a low pet count to group them together in an *Other* category. To ensure we don't lose any species-specific information, we'll create two versions of *Other*, 'Other Cat' and 'Other Dog'. \n",
    "\n",
    "Let's get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set threshold\n",
    "threshold = 50\n",
    "\n",
    "# Preserve list of Breeds with count greater equal to the threshold\n",
    "pet_breeds = pets_by_breed[pets_by_breed.Count >= threshold].Breed.tolist()\n",
    "\n",
    "# Create function to update breed column based on threshold\n",
    "def update_breed(row):\n",
    "    if (row[\"Breed\"] in pet_breeds):\n",
    "        return row[\"Breed\"]\n",
    "    else:\n",
    "        if (row[\"Species\"] == 'Cat'):\n",
    "            return 'Other Cat'\n",
    "        else:\n",
    "            return 'Other Dog'\n",
    "\n",
    "# Print number of unique breeds before update\n",
    "print(\"Number of unique breeds before: \" + str(df.Breed.nunique()))\n",
    "\n",
    "# Create copy of original df and apply function to update Breed\n",
    "df_new = df.copy()\n",
    "df_new[\"Breed\"] = df_new.apply(update_breed, axis=1)\n",
    "print(\"Number of unique breeds after: \" + str(df_new.Breed.nunique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've filtered out breeds with a count of pets below our threshold, let's replot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group pets by breed and aggregate claims data columns\n",
    "pets_by_breed = df_new.groupby(by=['Breed', 'Species']).agg({'PetId': ['count'],\n",
    "                                                         'AmtClaimsTotal': ['mean']}).reset_index()\n",
    "pets_by_breed.columns = ['Breed', 'Species', 'Count', 'AvgTotalClaims']\n",
    "\n",
    "# Calculate weighted average\n",
    "pets_by_breed[\"weighted_total\"] = pets_by_breed[\"Count\"] * pets_by_breed[\"AvgTotalClaims\"]\n",
    "weighted_avg = pets_by_breed[\"weighted_total\"].sum() / pets_by_breed[\"Count\"].sum()\n",
    "\n",
    "# Create a scatterplot showing count of breed vs avg total claims\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "\n",
    "sns.scatterplot(x=\"Count\", y=\"AvgTotalClaims\", data=pets_by_breed, hue='Species', hue_order=['Dog', 'Cat'],\n",
    "                alpha=0.7, size=\"Count\", sizes=(20, 200)).set(xlabel=\"Count of Pets\",\n",
    "                                                              ylabel=\"Average Total Claims, USD\")\n",
    "\n",
    "# Plot line showing the average for all pets\n",
    "plt.axhline(weighted_avg, color='g', linestyle='dashed', linewidth=1)\n",
    "plt.text(3500, 1525, \"All Breeds Weighted Average\")\n",
    "\n",
    "# Add title and display plot\n",
    "plt.title(\"Count of Pets vs. Average Total Claims Amount, by Breed and Species\", y=1.02, fontsize=14)\n",
    "plt.suptitle(\"\",\n",
    "             y=0.91, x=0.513, fontsize=11)\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After grouping together the breeds with a low pet count, we can see a lot less variability on the low end of the range. And in fact, it doesn't look like we have any breeds with \\$0 in average total claims which definitely feels more reasonable. \n",
    "\n",
    "All of that said, we do still see a fair bit of variability for breeds with less than about 1200 pets. For now, let's assume that variability is due to the fact that those breeds really are more expensive. We can come back and make adjustments later if we are getting poor results in our predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter df down the a subset of features\n",
    "cols = ['Breed', 'AgeYr1', 'AmtClaimsYr1', 'NumClaimsYr1']\n",
    "\n",
    "#Create a new dataframe and set the index to Breed\n",
    "df_new_scale = df_new[cols].set_index('Breed')\n",
    "\n",
    "#Save the breed labels\n",
    "df_new_index = df_new_scale.index\n",
    "\n",
    "#Save the column names \n",
    "df_new_columns = df_new_scale.columns\n",
    "df_new_scale.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "df_new_scale = scale(df_new_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new dataframe using saved column names\n",
    "df_new_scaled_df = pd.DataFrame(df_new_scale, columns=df_new_columns)\n",
    "df_new_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the scaling\n",
    "df_new_scaled_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify scaled std\n",
    "df_new_scaled_df.std(ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the PCA tranformation\n",
    "pets_pca = PCA().fit(df_new_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the result\n",
    "plt.subplots(figsize=(10, 6))\n",
    "plt.plot(pets_pca.explained_variance_ratio_.cumsum())\n",
    "plt.xlabel('Component #')\n",
    "plt.ylabel('Cumulative ratio variance')\n",
    "plt.title('Cumulative variance ratio explained by PCA components for pets summary statistics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results from PCA, we can see that about 85% of the variance is explained by the first 5 features of the data. This information may be helpful down the road in preprocessing and model creation as it provides us with a better foundation for understanding our data.\n",
    "\n",
    "# TODO\n",
    "* Should I do more with the PCA results here before moving on to the summary?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
